{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numbeo_scraper as ns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in population (1790 - 2010) and meetup info (2013-2014)\n",
    "df = pd.read_csv('data/1790-2010_MASTER.csv')\n",
    "df['city'] = df['City'].apply(lambda x: x.lower().replace('-', '_').replace(' ', '_'))\n",
    "df.set_index(['city'], inplace=True)\n",
    "df.sort_values(by=['2010'], ascending=False, inplace=True)\n",
    "df = df.head(100)\n",
    "\n",
    "df['STPLFIPS_2010']=df['STPLFIPS_2010'].astype(int)\n",
    "df.drop(['Name_2010','Place Type','CityST', 'City', 'ID','LAT_BING', 'LON_BING'], axis=1, inplace=True)\n",
    "\n",
    "columns = df.columns\n",
    "\n",
    "rj_df = pd.read_table('data/rj_metrics.txt')\n",
    "rj_df['state'] = (rj_df['City'].apply(lambda x: x.split(',')[-1]))\n",
    "rj_df['city'] = rj_df['City'].apply(lambda x: x.split(',')[0])\n",
    "rj_df['city'] = rj_df['city'].apply(lambda x: x.lower().replace('-', '_').replace(' ', '_'))\n",
    "rj_df.drop('City', axis =1, inplace=True)\n",
    "rj_df.set_index(['city'], inplace = True)\n",
    "\n",
    "new_df = pd.concat([df, rj_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clean and join bureau of economic affairs info\n",
    "\n",
    "bea_df = pd.read_csv('data/bea.csv', header=2)\n",
    "columns = bea_df.columns\n",
    "new_columns = [u'city', u'bea_state', u'bea_2009', u'bea_2010', u'bea_2011', u'bea_2012',\n",
    "       u'bea_2013', u'bea_2014', u'bea_what_is_this _crap']\n",
    "bea_df.columns = new_columns\n",
    "#bea_df = bea_df[1:]\n",
    "bea_df['city'] = bea_df['bea_state'].apply(lambda x: x.split(',')[0])\n",
    "bea_df['city'] = bea_df['city'].apply(lambda x: x.lower().replace('-', '_').replace(' ', '_'))\n",
    "bea_df['bea_state'] = bea_df['bea_state'].apply(lambda x: x.split(',')[-1])\n",
    "bea_df.set_index('city', inplace=True)\n",
    "\n",
    "next_df = pd.concat([new_df, bea_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "next_df.head()\n",
    "a = list(next_df.index)[:-2]\n",
    "b = list(next_df.ST)\n",
    "\n",
    "len(b)\n",
    "len(a)\n",
    "zipped = zip(a, b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state_bc</th>\n",
       "      <th>pct_college_grads_bc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>irvine</td>\n",
       "      <td>california</td>\n",
       "      <td>65.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seattle</td>\n",
       "      <td>washington</td>\n",
       "      <td>55.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>plano</td>\n",
       "      <td>texas</td>\n",
       "      <td>54.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>madison</td>\n",
       "      <td>wisconsin</td>\n",
       "      <td>52.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>scottsdale</td>\n",
       "      <td>arizona</td>\n",
       "      <td>52.2%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         city    state_bc pct_college_grads_bc\n",
       "0      irvine  california                65.0%\n",
       "1     seattle  washington                55.8%\n",
       "2       plano       texas                54.0%\n",
       "3     madison   wisconsin                52.9%\n",
       "4  scottsdale     arizona                52.2%"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.biggestuscities.com/demographics/us/education-college-graduates-by-top-100-city'\n",
    "# This works, don't break!'\n",
    "\n",
    "def get_grad_data(url, cols, skip_rows=4):\n",
    "    file_name = url.split('/')[-1].replace('-', '_')\n",
    "    path = os.getcwd()+'/data/biggestuscities' #/{}'.format(file_name)\n",
    "    file_path = '{}/{}.csv'.format(path, file_name)\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    if not os.path.isfile(file_path):\n",
    "        soup = ns.get_pages(url)\n",
    "        tabs =[]\n",
    "        table = soup[0].findAll('table')\n",
    "\n",
    "        for tag in table:\n",
    "            tabs.append(tag.text)\n",
    "\n",
    "        d = [t.replace(\"\\n\",\",\").strip() for t in tabs][-1]\n",
    "        d = d.split(' ')\n",
    "        t = [item for item in d if item != '']\n",
    "        t_done = [item.replace(',',' ').strip()  for item in t]\n",
    "        just_table = t_done[skip_rows:-9]\n",
    "        bad_item_list = ['(adsbygoogle', '=', 'window.adsbygoogle', '||', '[]).push({', '});', 'San',\n",
    "                        'District', 'Of', 'North', 'St.', 'City', 'New', 'Springs', 'Urban', 'Beach',\n",
    "                         'Rouge', 'Los', 'El', 'Vista', 'County', 'Fort', 'Las', 'Christi', 'Ana']\n",
    "\n",
    "        for item in bad_item_list:\n",
    "            just_table.remove(item)\n",
    "\n",
    "        just_table = [item for item in just_table if item not in bad_item_list if item]\n",
    "        just_table = [item.replace('Francisco', 'san_francisco') for item in just_table]\n",
    "        just_table = [item.replace('Carolina', 'north_carolina') for item in just_table]\n",
    "        just_table = [item.replace('Baton', 'baton_rouge') for item in just_table]\n",
    "        just_table = [item.replace('Chula', 'chula_vista') for item in just_table]\n",
    "        just_table = [item.replace('Worth', 'fort_worth') for item in just_table]\n",
    "        just_table = [item.replace('Christi', 'corpus_christi') for item in just_table]\n",
    "        just_table = [item.replace('Santa', 'santa_ana') for item in just_table]\n",
    "        just_table = [item.replace('Vegas', 'las_vegas') for item in just_table]\n",
    "        just_table = [item.replace('Bernadino', 'san_bernadino') for item in just_table]\n",
    "        just_table = [item.replace('Columbia', 'dc') for item in just_table]\n",
    "        just_table = [item.replace('Diego', 'san_diego') for item in just_table]\n",
    "        just_table = [item.replace('Jersey', 'new_jersey') for item in just_table]\n",
    "        just_table = [item.replace('Orleans', 'new_orleans') for item in just_table]\n",
    "        just_table = [item.replace('York', 'new_york') for item in just_table]\n",
    "        just_table = [item.lower() for item in just_table]\n",
    "\n",
    "        chunks = [just_table[x:x+4] for x in xrange(0, len(just_table), 4)]\n",
    "        df = pd.DataFrame(chunks)\n",
    "        df.columns = cols\n",
    "        file_name = url.split('/')[-1].replace('-', '_')\n",
    "        df=df.drop('rank', axis=1)\n",
    "        df.set_index('city', inplace=True)\n",
    "        df_csv = df.copy()\n",
    "        df_csv.to_csv(file_path)\n",
    "        return df\n",
    "    else:\n",
    "        df = pd.read_csv(file_path)\n",
    "        return df\n",
    "\n",
    "cols = ['rank', 'city','state_bc','pct_college_grads_bc']\n",
    "df = get_grad_data(url, cols)\n",
    "another_df = pd.concat([next_df, df], axis=0)\n",
    "\n",
    "#df.to_csv('/data/biggestuscities/{}'.format(filename))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     492\n",
       "False    100\n",
       "Name: pct_college_grads_bc, dtype: int64"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "another_df['pct_college_grads_bc'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/IXChris/Desktop/G/capstone/data/biggestuscities/people_foreign_born_by_top_100_city.csv'"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.biggestuscities.com/demographics/us/education-college-graduates-by-top-100-city'\n",
    "cols = ['rank', 'city','state_fb','pct_foreign_born']\n",
    "df2 = get_grad_data(url, cols, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#subset by dense rows\n",
    "meetup_df = new_df[new_df['Pop'].notnull()]\n",
    "cities = list(meetup_df.index)\n",
    "\n",
    "# fix column names\n",
    "cols = meetup_df.columns\n",
    "cols = [item.lower().replace(' ', '_') for item in cols]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
