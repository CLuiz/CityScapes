{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numbeo_scraper as ns\n",
    "import get_bea_data as gbd\n",
    "import population_cleanup as pc\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in population (1790 - 2010) and rj metrics meetup info (2013-2014) and merge df's\n",
    "\n",
    "pop_df = pc.get_pop_data('data/1790-2010_MASTER.csv')\n",
    "rj_df = pc.get_rj_data('data/rj_metrics.txt')\n",
    "new_df = pd.concat([pop_df, rj_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clean and join bureau of economic affairs info\n",
    "\n",
    "raw_bea = gbd.get_bea_data('http://www.bea.gov/newsreleases/regional/gdp_metro/2015/xls/gdp_metro0915.xls')\n",
    "bea_df = gbd.clean_me(raw_bea)\n",
    "next_df = pd.concat([new_df, bea_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state_bc</th>\n",
       "      <th>pct_college_grads_bc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>irvine</td>\n",
       "      <td>california</td>\n",
       "      <td>65.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seattle</td>\n",
       "      <td>washington</td>\n",
       "      <td>55.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>plano</td>\n",
       "      <td>texas</td>\n",
       "      <td>54.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>madison</td>\n",
       "      <td>wisconsin</td>\n",
       "      <td>52.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>scottsdale</td>\n",
       "      <td>arizona</td>\n",
       "      <td>52.2%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         city    state_bc pct_college_grads_bc\n",
       "0      irvine  california                65.0%\n",
       "1     seattle  washington                55.8%\n",
       "2       plano       texas                54.0%\n",
       "3     madison   wisconsin                52.9%\n",
       "4  scottsdale     arizona                52.2%"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.biggestuscities.com/demographics/us/education-college-graduates-by-top-100-city'\n",
    "# This works, don't break!'\n",
    "\n",
    "def get_grad_data(url, cols, skip_rows=4):\n",
    "    file_name = url.split('/')[-1].replace('-', '_')\n",
    "    path = os.getcwd()+'/data/biggestuscities' #/{}'.format(file_name)\n",
    "    file_path = '{}/{}.csv'.format(path, file_name)\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    if not os.path.isfile(file_path):\n",
    "        soup = ns.get_pages(url)\n",
    "        tabs =[]\n",
    "        table = soup[0].findAll('table')\n",
    "\n",
    "        for tag in table:\n",
    "            tabs.append(tag.text)\n",
    "\n",
    "        d = [t.replace(\"\\n\",\",\").strip() for t in tabs][-1]\n",
    "        d = d.split(' ')\n",
    "        t = [item for item in d if item != '']\n",
    "        t_done = [item.replace(',',' ').strip()  for item in t]\n",
    "        just_table = t_done[skip_rows:-9]\n",
    "        bad_item_list = ['(adsbygoogle', '=', 'window.adsbygoogle', '||', '[]).push({', '});', 'San',\n",
    "                        'District', 'Of', 'North', 'St.', 'City', 'New', 'Springs', 'Urban', 'Beach',\n",
    "                         'Rouge', 'Los', 'El', 'Vista', 'County', 'Fort', 'Las', 'Christi', 'Ana']\n",
    "\n",
    "        for item in bad_item_list:\n",
    "            just_table.remove(item)\n",
    "\n",
    "        just_table = [item for item in just_table if item not in bad_item_list if item]\n",
    "        just_table = [item.replace('Francisco', 'san_francisco') for item in just_table]\n",
    "        just_table = [item.replace('Carolina', 'north_carolina') for item in just_table]\n",
    "        just_table = [item.replace('Baton', 'baton_rouge') for item in just_table]\n",
    "        just_table = [item.replace('Chula', 'chula_vista') for item in just_table]\n",
    "        just_table = [item.replace('Worth', 'fort_worth') for item in just_table]\n",
    "        just_table = [item.replace('Christi', 'corpus_christi') for item in just_table]\n",
    "        just_table = [item.replace('Santa', 'santa_ana') for item in just_table]\n",
    "        just_table = [item.replace('Vegas', 'las_vegas') for item in just_table]\n",
    "        just_table = [item.replace('Bernadino', 'san_bernadino') for item in just_table]\n",
    "        just_table = [item.replace('Columbia', 'dc') for item in just_table]\n",
    "        just_table = [item.replace('Diego', 'san_diego') for item in just_table]\n",
    "        just_table = [item.replace('Jersey', 'new_jersey') for item in just_table]\n",
    "        just_table = [item.replace('Orleans', 'new_orleans') for item in just_table]\n",
    "        just_table = [item.replace('York', 'new_york') for item in just_table]\n",
    "        just_table = [item.lower() for item in just_table]\n",
    "\n",
    "        chunks = [just_table[x:x+4] for x in xrange(0, len(just_table), 4)]\n",
    "        df = pd.DataFrame(chunks)\n",
    "        df.columns = cols\n",
    "        file_name = url.split('/')[-1].replace('-', '_')\n",
    "        df=df.drop('rank', axis=1)\n",
    "        df.set_index('city', inplace=True)\n",
    "        df_csv = df.copy()\n",
    "        df_csv.to_csv(file_path)\n",
    "        return df\n",
    "    else:\n",
    "        df = pd.read_csv(file_path)\n",
    "        return df\n",
    "\n",
    "cols = ['rank', 'city','state_bc','pct_college_grads_bc']\n",
    "df = get_grad_data(url, cols)\n",
    "another_df = pd.concat([next_df, df], axis=0)\n",
    "\n",
    "#df.to_csv('/data/biggestuscities/{}'.format(filename))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 'irvine',\n",
       "       'seattle', 'plano', 'madison', 'scottsdale', 'san_francisco',\n",
       "       'washington', 'fremont', 'raleigh', 'durham', 'atlanta',\n",
       "       'minneapolis', 'austin', 'boston', 'portland', 'denver',\n",
       "       'san_diego', 'new_jersey', 'charlotte', 'chandler',\n",
       "       'lexington-fayette', 'gilbert', 'oakland', 'paul', 'boise', 'jose',\n",
       "       'colorado', 'lincoln', 'greensboro', 'pittsburgh', 'new_york',\n",
       "       'nashville-davidson', 'honolulu', 'irving', 'chicago',\n",
       "       'baton_rouge', 'columbus', 'virginia', 'new_orleans', 'anchorage',\n",
       "       'albuquerque', 'tampa', 'omaha', 'orlando', 'winston-salem',\n",
       "       'cincinnati', 'angeles', 'henderson', 'kansas', 'tulsa', 'lubbock',\n",
       "       'sacramento', 'arlington', 'dallas', 'long', 'houston', 'reno',\n",
       "       'chesapeake', 'oklahoma', 'wichita', 'petersburg', 'louis',\n",
       "       'indianapolis', 'chula_vista', 'aurora', 'louisville/jefferson',\n",
       "       'fort_worth', 'baltimore', 'wayne', 'phoenix', 'norfolk', 'tucson',\n",
       "       'jacksonville', 'antonio', 'mesa', 'anaheim', 'memphis',\n",
       "       'philadelphia', 'buffalo', 'miami', 'paso', 'riverside',\n",
       "       'las_vegas', 'garland', 'glendale', 'milwaukee', 'birmingham',\n",
       "       'corpus', 'fresno', 'bakersfield', 'laredo', 'toledo', 'stockton',\n",
       "       'las_vegas', 'cleveland', 'hialeah', 'bernardino', 'newark',\n",
       "       'detroit', 'santa_ana'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "another_df['city'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Index' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-52c8f1b3851d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manother_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Index' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "another_df.index.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/IXChris/Desktop/G/capstone/data/biggestuscities/people_foreign_born_by_top_100_city.csv'"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.biggestuscities.com/demographics/us/education-college-graduates-by-top-100-city'\n",
    "cols = ['rank', 'city','state_fb','pct_foreign_born']\n",
    "df2 = get_grad_data(url, cols, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#subset by dense rows\n",
    "meetup_df = new_df[new_df['Pop'].notnull()]\n",
    "cities = list(meetup_df.index)\n",
    "\n",
    "# fix column names\n",
    "cols = meetup_df.columns\n",
    "cols = [item.lower().replace(' ', '_') for item in cols]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
