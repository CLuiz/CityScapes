{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numbeo_scraper as ns\n",
    "import get_bea_data as gbd\n",
    "import population_cleanup as pc\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 40)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in population (1790 - 2010) and rj metrics meetup info (2013-2014) and merge df's\n",
    "\n",
    "pop_df = pc.get_pop_data('data/1790-2010_MASTER.csv')\n",
    "rj_df = pc.get_rj_data('data/rj_metrics.txt')\n",
    "new_df = pd.concat([pop_df, rj_df], axis=1)\n",
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(492, 48)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean and join bureau of economic affairs info\n",
    "\n",
    "raw_bea = gbd.get_bea_data('http://www.bea.gov/newsreleases/regional/gdp_metro/2015/xls/gdp_metro0915.xls')\n",
    "bea_df = gbd.clean_me(raw_bea)\n",
    "next_df = pd.concat([new_df, bea_df], axis=0)\n",
    "next_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(592, 50)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.biggestuscities.com/demographics/us/education-college-graduates-by-top-100-city'\n",
    "# This works, don't break!'\n",
    "\n",
    "def get_grad_data(url, cols, skip_rows=4):\n",
    "    file_name = url.split('/')[-1].replace('-', '_')\n",
    "    path = os.getcwd()+'/data/biggestuscities' #/{}'.format(file_name)\n",
    "    file_path = '{}/{}.csv'.format(path, file_name)\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    if not os.path.isfile(file_path):\n",
    "        soup = ns.get_pages(url)\n",
    "        tabs =[]\n",
    "        table = soup[0].findAll('table')\n",
    "\n",
    "        for tag in table:\n",
    "            tabs.append(tag.text)\n",
    "\n",
    "        d = [t.replace(\"\\n\",\",\").strip() for t in tabs][-1]\n",
    "        d = d.split(' ')\n",
    "        t = [item for item in d if item != '']\n",
    "        t_done = [item.replace(',',' ').strip()  for item in t]\n",
    "        just_table = t_done[skip_rows:-9]\n",
    "        bad_item_list = ['(adsbygoogle', '=', 'window.adsbygoogle', '||', '[]).push({', '});', 'San',\n",
    "                        'District', 'Of', 'North', 'St.', 'City', 'New', 'Springs', 'Urban', 'Beach',\n",
    "                         'Rouge', 'Los', 'El', 'Vista', 'County', 'Fort', 'Las', 'Christi', 'Ana']\n",
    "\n",
    "        for item in bad_item_list:\n",
    "            just_table.remove(item)\n",
    "\n",
    "        just_table = [item for item in just_table if item not in bad_item_list if item]\n",
    "        just_table = [item.replace('Francisco', 'san_francisco') for item in just_table]\n",
    "        just_table = [item.replace('Carolina', 'north_carolina') for item in just_table]\n",
    "        just_table = [item.replace('Baton', 'baton_rouge') for item in just_table]\n",
    "        just_table = [item.replace('Chula', 'chula_vista') for item in just_table]\n",
    "        just_table = [item.replace('Worth', 'fort_worth') for item in just_table]\n",
    "        just_table = [item.replace('Christi', 'corpus_christi') for item in just_table]\n",
    "        just_table = [item.replace('Santa', 'santa_ana') for item in just_table]\n",
    "        just_table = [item.replace('Vegas', 'las_vegas') for item in just_table]\n",
    "        just_table = [item.replace('Bernadino', 'san_bernadino') for item in just_table]\n",
    "        just_table = [item.replace('Columbia', 'dc') for item in just_table]\n",
    "        just_table = [item.replace('Diego', 'san_diego') for item in just_table]\n",
    "        just_table = [item.replace('Jersey', 'new_jersey') for item in just_table]\n",
    "        just_table = [item.replace('Orleans', 'new_orleans') for item in just_table]\n",
    "        just_table = [item.replace('York', 'new_york') for item in just_table]\n",
    "        just_table = [item.lower() for item in just_table]\n",
    "\n",
    "        chunks = [just_table[x:x+4] for x in xrange(0, len(just_table), 4)]\n",
    "        df = pd.DataFrame(chunks)\n",
    "        df.columns = cols\n",
    "        file_name = url.split('/')[-1].replace('-', '_')\n",
    "        df=df.drop('rank', axis=1)\n",
    "        df.set_index('city', inplace=True)\n",
    "        df_csv = df.copy()\n",
    "        df_csv.to_csv(file_path)\n",
    "        return df\n",
    "    else:\n",
    "        df = pd.read_csv(file_path)\n",
    "        df.set_index('city', inplace=True)\n",
    "        return df\n",
    "\n",
    "cols = ['rank', 'city','state_bc','pct_college_grads_bc']\n",
    "df = get_grad_data(url, cols)\n",
    "another_df = pd.concat([next_df, df], axis=0)\n",
    "\n",
    "#df.to_csv('/data/biggestuscities/{}'.format(filename))\n",
    "another_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/IXChris/Desktop/G/capstone/data/biggestuscities/people_foreign_born_by_top_100_city.csv'"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.biggestuscities.com/demographics/us/education-college-graduates-by-top-100-city'\n",
    "cols = ['rank', 'city','state_fb','pct_foreign_born']\n",
    "df2 = get_grad_data(url, cols, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#subset by dense rows\n",
    "meetup_df = new_df[new_df['Pop'].notnull()]\n",
    "cities = list(meetup_df.index)\n",
    "\n",
    "# fix column names\n",
    "cols = meetup_df.columns\n",
    "cols = [item.lower().replace(' ', '_') for item in cols]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
